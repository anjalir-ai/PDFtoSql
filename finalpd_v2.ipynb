{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4cmXo9FFXri",
        "outputId": "befe58ee-a050-4756-8688-08786a21c7f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.9.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from tabula-py) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.25.2)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from tabula-py) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.16.0)\n",
            "Installing collected packages: tabula-py\n",
            "Successfully installed tabula-py-2.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tabula-py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tabula\n",
        "import json\n",
        "# Path to your PDF file\n",
        "pdf_path = '/content/42xxx_xxxxxxx_xxxx.pdf'"
      ],
      "metadata": {
        "id": "JZ0s6pdKZnZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tabula to read tables from the PDF\n",
        "# This returns a list of DataFrame objects, one for each table detected in the PDF.\n",
        "tables = tabula.read_pdf(pdf_path, pages=\"all\", multiple_tables=True)\n",
        "# Convert the table data to JSON\n",
        "# This will create a list of JSON objects if there are multiple tables\n",
        "json_tables = [table.to_json(orient=\"records\") for table in tables]\n",
        "# Load the JSON data of the first table into Python dictionary objects\n",
        "table_data_1=json.loads(json_tables[0])\n",
        "# Convert the second row of the first table to a list of (column_name, value) tuples\n",
        "u=list(table_data_1[1].items())\n",
        "# Convert the fourth row of the first table to a list of (column_name, value) tuples\n",
        "v=list(table_data_1[3].items())\n",
        "# Convert the third row of the first table to a list of (column_name, value) tuples\n",
        "t=list(table_data_1[2].items())"
      ],
      "metadata": {
        "id": "1h6dqIhUZ3Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the JSON data of the second table into Python dictionary objects\n",
        "table_data_2 = json.loads(json_tables[1])\n",
        "# Load the JSON data of the third table into Python dictionary objects\n",
        "table_data_3 = json.loads(json_tables[2])\n",
        "# Convert the first row of the second table to a list of (column_name, value) tuples\n",
        "e=list(table_data_2[0].items())\n",
        "# Convert the second row of the second table to a list of (column_name, value) tuples\n",
        "d=list(table_data_2[1].items())\n",
        "# Convert the first row of the third table to a list of (column_name, value) tuples\n",
        "z = list(table_data_3[0].values())"
      ],
      "metadata": {
        "id": "jgsXCG3PaDC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(e)==1 :\n",
        "   # If the length of the list 'e' is 1, extract the relevant information from the first item of each list.\n",
        "  desc = e[0][1].split('Platform/MODU/project name ')[1]\n",
        "  mc = d[0][1].split('OCS-G block and area ')[1]\n",
        "  cname = u[0][1].split('Name of operator contact ')[1]\n",
        "  cemail = v[0][1].split('E-mail address for notifications ')[1]\n",
        "  cphone = t[0][1].split('Phone number of operator contact ')[1]\n",
        "  stattype = e[0][0].split('Station type (Spar, TLP, Semi, MODU, Mooring) ')[1]\n",
        "  ins = z[0].split('Instrument model (e.g. RDI 75kHz BB) ')[1]\n",
        "elif len(e)==2:\n",
        "   # If the length of the list 'e' is 2, check if the second item's value is None.\n",
        "  if e[1][1] is None:\n",
        "    # If the second item's value is None, extract the relevant information from the first item of each list.\n",
        "    desc = e[0][1].split('Platform/MODU/project name ')[1]\n",
        "    mc = d[0][1].split('OCS-G block and area ')[1]\n",
        "    cname = u[0][1].split('Name of operator contact ')[1]\n",
        "    cemail = v[0][1].split('E-mail address for notifications ')[1]\n",
        "    cphone = t[0][1].split('Phone number of operator contact ')[1]\n",
        "    stattype = e[0][0].split('Station type (Spar, TLP, Semi, MODU, Mooring) ')[1]\n",
        "    ins = z[0].split('Instrument model (e.g. RDI 75kHz BB) ')[1]\n",
        "  else:\n",
        "    # If the second item's value is not None, extract the relevant information directly from the second item of each list.\n",
        "    desc = e[1][1]\n",
        "    mc = d[1][1]\n",
        "    cname = u[1][1]\n",
        "    cemail = v[1][1]\n",
        "    cphone = t[1][1]\n",
        "    stattype = e[1][0]\n",
        "    ins = z[1]\n",
        "# Now you have extracted the following information:\n",
        "# desc: Description of the platform/MODU/project name\n",
        "# mc: OCS-G block and area\n",
        "# cname: Name of the operator contact\n",
        "# cemail: E-mail address for notifications\n",
        "# cphone: Phone number of the operator contact\n",
        "# stattype: Station type (Spar, TLP, Semi, MODU, Mooring)\n",
        "# ins: Instrument model (e.g. RDI 75kHz BB)"
      ],
      "metadata": {
        "id": "52jZm6awaIWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the fourth row of the second table as a list of values\n",
        "x = list(table_data_2[3].values())\n",
        "# Check if the first item of the list 'x' is 'Latitude (Deg, Min, Sec)'\n",
        "if x[0] == 'Latitude (Deg, Min, Sec)' :\n",
        "  # If true, remove ' N' from the second item and strip any leading/trailing whitespace\n",
        "  lat = list(x)[1].replace(' N','').strip()\n",
        "else :\n",
        "  # Otherwise, split the first item at 'Latitude (Deg, Min, Sec) ' and remove trailing spaces\n",
        "  lat = x[0].split('Latitude (Deg, Min, Sec) ')[1].rsplit(' ', 1)[0]\n",
        "# Extract the fifth row of the second table as a list of values\n",
        "y = list(table_data_2[4].values())\n",
        "# Check the length of the list 'y' and handle accordingly\n",
        "if len(y) == 1:\n",
        "  # If there's only one item, split and extract the longitude value\n",
        "  lon = y[0].split('Longitude (Deg, Min, Sec) ')[1]\n",
        "elif len(y) == 2 and y[1] is None:\n",
        "  # If there are two items and the second item is None, extract from the first item\n",
        "  lon = y[0].split('Longitude (Deg, Min, Sec) ')[1]\n",
        "elif len(y) >= 2:\n",
        "  # If there are two or more items, remove ' W' from the second item and strip whitespace\n",
        "  lon = y[1].replace(' W', '').strip()\n",
        "# Define a function to convert DMS (Degrees, Minutes, Seconds) to decimal degrees\n",
        "def dms_to_decimal(dms):\n",
        "    # Remove common non-numeric characters\n",
        "    dms = dms.replace('°', ' ').replace('’', ' ').replace('\\'', ' ').replace('”', ' ').replace('\"', ' ')\n",
        "    parts = dms.split()\n",
        "    #print(parts)\n",
        "    degrees = float(parts[0])\n",
        "    minutes = float(parts[1])\n",
        "    seconds = float(parts[2])\n",
        "    # Convert DMS to decimal degrees\n",
        "    decimal = degrees + (minutes / 60) + (seconds / 3600)\n",
        "    return decimal\n",
        "# Example usage\n",
        "lat_dms = lat\n",
        "lon_dms = lon\n",
        "# Convert the DMS values to decimal degrees\n",
        "lat_decimal = dms_to_decimal(lat_dms)\n",
        "lon_decimal = dms_to_decimal(lon_dms)\n",
        "# Round the decimal values to 4 decimal places\n",
        "lat_val = round(lat_decimal, 4)\n",
        "lon_val = round(lon_decimal, 4)"
      ],
      "metadata": {
        "id": "1IReH3MEaU01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to hold all transformed data from each table\n",
        "all_transformed_data = []\n",
        "#Iterate over each JSON string in json_tables\n",
        "for json_table in json_tables:\n",
        "     # Parse the JSON string back into a Python object (list of dictionaries)\n",
        "     table_data = json.loads(json_table)\n",
        "     # Initialize an empty dictionary for the current table's transformed data\n",
        "     transformed_data = {}\n",
        "     # Iterate over each row in the current table\n",
        "     for row in table_data:\n",
        "         # Check if the row has at least two values\n",
        "         if len(row.values()) >= 2:\n",
        "           # Extract the first key and value from the row\n",
        "             key = list(row.keys())[0]  # The descriptor (e.g., \"Operator URL\")\n",
        "             value = list(row.values())[0]  # The corresponding detail (e.g., \"www.shell.com\")\n",
        "             # Add the key-value pair to the transformed_data dictionary\n",
        "             transformed_data[key] = value\n",
        "     # Add the transformed data for the current table to the list\n",
        "     if transformed_data:\n",
        "         all_transformed_data.append(transformed_data)\n",
        "    # Now you have a list 'all_transformed_data' containing dictionaries with transformed data from each table"
      ],
      "metadata": {
        "id": "nV5eqbESao0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the PDF name from the path\n",
        "pdf_name = pdf_path.split('/')[-1]\n",
        "\n",
        "# Getting the first five characters of the PDF name\n",
        "platform_name = pdf_name[:5]\n",
        "\n",
        "# Extracting latitude and longitude directly as strings\n",
        "try:\n",
        "  # Constructing the SQL statement to update the platform table\n",
        "     sql_statement_platform = \"UPDATE platform SET description = '\"+platform_name+\" - \"+desc+\" - \"+mc+\"', local = '\"+platform_name+\" - \"+desc+\" - \"+mc+\"', loc_lat = \"+str(lat_val)+\", loc_lon = -\"+str(lon_val)+\", contactName = '\"+cname+\"', contactEmail = '\"+cemail+\"', Phone = '\"+cphone+\"', ttype = '\"+stattype+\"' WHERE name = '\"+platform_name+\"'\"\n",
        "      # Constructing the SQL statement to update the sensor table\n",
        "     sql_statement_sensor = \"UPDATE sensor SET instrument='\"+ins+\"' WHERE rowid= and platformId= ;\"\n",
        "      # Printing the constructed SQL statements\n",
        "     print(sql_statement_platform)\n",
        "     print(sql_statement_sensor)\n",
        "except KeyError as e:\n",
        "  # Handling KeyError if a key is not found in the table data\n",
        "   print(f\"KeyError: {e} - The key was not found in the table data.\")\n",
        "except IndexError as e:\n",
        "   # Handling IndexError if the expected table or data is not found\n",
        "   print(f\"IndexError: {e} - The expected table was not found.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3JxJyoWayfI",
        "outputId": "24f2214d-0679-48d2-ee39-c947901f5ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UPDATE platform SET description = '42902 - Deepwater Proteus - MC809', local = '42902 - Deepwater Proteus - MC809', loc_lat = 28.159, loc_lon = -89.1322, contactName = 'Keith Kurrus', contactEmail = 'HoustonOpsEHI@rpsgroup.com', Phone = '281-495-0883', ttype = 'MODU' WHERE name = '42902'\n",
            "UPDATE sensor SET instrument='RDI 38kHz DR OO III' WHERE rowid= and platformId= ;\n"
          ]
        }
      ]
    }
  ]
}